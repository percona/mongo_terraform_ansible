# Deploy MongoDB clusters using Ansible
## Quick guide
1. Create an inventory file (or use the one generated by Terraform)
2. Edit the [all variables file](group_vars/all)
3. Run the playbook, specifying the key pair for accessing the storage bucket for backups
```
ansible-playbook main.yml -i inventory --extra-vars "access_key_id=***** secret_access_key=******"
```

## Inventory file

- Keep a separate inventory file per environment (for example dev, test, prod).
- If you have more than one cluster per environment, then keep one inventory per cluster as well (for example devrs1, devrs2, devshard1, devshard2).
- On each inventory file, we have to specify groups for each shard's replicaset (name them shardXXXX), as well as the config servers (cfg) and mongos routers (mongos). 
- For each standalone replicaset you should name them rsXXXX.
- You can specify a server in more than one group only for the case of deploying the mongos + config server combination. Any other combinations are currently not supported and cause execution to fail.

- Example of inventory for a sharded cluster:
```
[cfg]
dev-mongo-cfg00 mongodb_primary=True
dev-mongo-cfg01
dev-mongo-cfg02

[shard0]
dev-mongo-shard00svr0 mongodb_primary=True
dev-mongo-shard00svr1
dev-mongo-shard00svr2
[shard1]
dev-mongo-shard01svr0 mongodb_primary=True
dev-mongo-shard01svr1
dev-mongo-shard01svr2

[mongos]
dev-mongo-router00
```

- Example of inventory for a single replicaset:
```
[rs1]
host11 mongodb_primary=True
host12
host13
```

The `mongodb_primary` tag will make that server become the primary by giving it higher priority in the replicaset configuration.
Only 1 sharded cluster per inventory is supported at this time.

## Configuration
* The [all variables file](group_vars/all) contains all the user-modifiable parameters. Each of these come with a small description to clarify the purpose, unless it is self-explanatory. 
You should review and modify this file before making the deployment.

Note: PMM user and password are used to login to PMM UI via the web browser. If you intend to change the PMM credentials on the variables file (defaults are admin/admin), you will need to login to PMM via the web browser and change the PMM password there first, otherwise the playbook will fail. 
 
## Running
* The playbook is meant to handle a deployment from scratch, unless run with some specific tags (e.g. conf). So be extra careful if you are running it against servers that already have data.

- Available tags:
  - backup
    - Deploys & configures the pbm agent
  - monitoring
    - Deploys pmm2 client and registers with a pmm server

* Deploy a replica set or sharded cluster from scratch:
```
ansible-playbook main.yml -i inventory --extra-vars "access_key_id=********* secret_access_key=**********"
```
* Add a new shard (e.g. shard3) to an existing cluster:
```
ansible-playbook main.yml -i inventory --limit shard3
```
* Deploy skip the monitoring and backup parts
```
ansible-playbook main.yml -i inventory --skip-tags monitoring,backup
```

## Cleanup
* If you want cleanup a failed deploy, usually stopping mongod/mongos components and removing the datadir content is enough e.g.
```
service mongos stop; service mongod stop; rm -rf /var/lib/mongo/*
```

You can also try running the `reset.yml` playbook
```
ansible-playbook reset.yml -i inventory
```

## Connecting 
* Connection string example with TLS
```
mongo --tls --tlsCAFile /tmp/test-ca.pem --tlsCertificateKeyFile /tmp/test-client.pem --port 27017 --host ip-10-0-1-199.ec2.internal -u root -p percona
```
* Listing existing backups with TLS
```
pbm list --mongodb-uri "mongodb://pbm:secretpwd@ip-10-0-1-199.ec2.internal:27019/?tls=true&tlsCertificateKeyFile=/tmp/test-server.pem&tlsCAFile=/tmp/test-ca.pem"
```
